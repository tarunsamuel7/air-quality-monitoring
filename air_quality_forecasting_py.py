# -*- coding: utf-8 -*-
"""air_quality_forecasting.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FncDeer3pGKB3aTp5rWZ4jNPwgC0K7uu
"""

!pip install streamlit

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.models import load_model
from sklearn.preprocessing import MinMaxScaler

# Load Data
@st.cache
def load_data(file_path):
    data = pd.read_csv(file_path)
    data['Date'] = pd.to_datetime(data['Date'])
    data.set_index('Date', inplace=True)
    return data

# Load ML Model
@st.cache(allow_output_mutation=True)
def load_ml_model(model_path):
    model = load_model(model_path)
    return model

# Function to normalize data
def normalize_data(data, scaler):
    data_scaled = scaler.fit_transform(data)
    return data_scaled

# Function to create sequences
def create_sequences(data, sequence_length):
    sequences = []
    for i in range(len(data) - sequence_length):
        sequences.append(data[i:i+sequence_length])
    return np.array(sequences)

# Streamlit app
st.title("Air Quality Data Analysis and Forecasting")

# Load specific paths
data_path1 = "/content/ancona_data.csv"
data_path2 = "/content/athens_data.csv"
model_path = "/content/Merged_Data_Preprocessing_and_ARIMA_Model_XGBoost model.ipynb"

df1 = load_data(data_path1)
df2 = load_data(data_path2)
model = load_ml_model(model_path)

st.subheader("Ancona Data")
st.write(df1.head())

st.subheader("Athens Data")
st.write(df2.head())

# Display correlation matrix
st.subheader("Correlation Matrix")
numerical_columns = ['NO2', 'O3', 'PM10', 'PM2.5', 'Wind-Speed (U)', 'Wind-Speed (V)', 'Dewpoint Temp', 'Soil Temp', 'Total Precipitation', 'Vegetation (High)', 'Vegetation (Low)', 'Temperature', 'Relative Humidity']
corr_matrix = df1[numerical_columns].corr()
fig, ax = plt.subplots()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)
st.pyplot(fig)

# Predict for next 60 days using ML Model
st.subheader("ML Model Forecasting")
pollutant = st.selectbox("Select pollutant for ML forecasting", ['NO2', 'O3', 'PM10', 'PM2.5'])
sequence_length = st.number_input("Sequence Length", min_value=1, max_value=100, value=30)
forecast_days = st.number_input("Number of Days to Forecast", min_value=1, max_value=365, value=60)

scaler = MinMaxScaler()

df1_scaled = normalize_data(df1[[pollutant]], scaler)
sequences = create_sequences(df1_scaled, sequence_length)

predictions = []
current_sequence = sequences[-1]

for _ in range(forecast_days):
    prediction = model.predict(np.expand_dims(current_sequence, axis=0))
    predictions.append(prediction[0][0])
    current_sequence = np.append(current_sequence[1:], prediction[0])

predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))
future_dates = pd.date_range(start=df1.index[-1] + pd.Timedelta(days=1), periods=forecast_days, freq='D')

forecast_df = pd.DataFrame(data=predictions, index=future_dates, columns=[pollutant])

fig, ax = plt.subplots()
ax.plot(df1.index, df1[pollutant], label='Historical Data')
ax.plot(forecast_df.index, forecast_df[pollutant], label='Forecast')
ax.legend()
st.pyplot(fig)

st.write(forecast_df)